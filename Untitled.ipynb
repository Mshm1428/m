{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f5aff3-e764-456c-9975-b09169503823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting alternative trend fetch (HN + Reddit) ...\n",
      "Saved 40 trends to trends_list.txt\n",
      "1. Bazzite: The Next Generation Of Linux Gaming\n",
      "2. Show Hn: Boing\n",
      "3. Zigbook Is Plagiarizing The Zigtools Playground\n",
      "4. All It Takes Is For One To Work Out\n",
      "5. Meshtastic\n",
      "6. Landlock-ing Linux\n",
      "7. The Http Query Method\n",
      "8. Learning Feynman S Trick For Integrals\n",
      "9. Blender Facial Animation Tool What Else Should It Do\n",
      "10. A New Little Prince Museum Has Opened Its Doors In Switzerland\n",
      "11. Scala\n",
      "12. Americans No Longer See Four-year College Degrees As Worth The Cost\n",
      "13. Show Hn: Nano Pdf A Cli Tool To Edit Pdfs With Gemini S Nano Banana\n",
      "14. Datacenters In Space Aren T Going To Work\n",
      "15. Be Like Clippy\n",
      "16. Matrix Core Programming On Amd Cdna Architecture\n",
      "17. An Update On The Farphone S Battery\n",
      "18. Rare X-ray Images Of A 4 5-ton Satellite That Returned Intact From Space\n",
      "19. Testing Shows Automotive Glassbreakers Can T Break Modern Automotive Glass\n",
      "20. Leak Confirms Openai Is Preparing Ads On Chatgpt For Public Roll Out\n",
      "21. The Origins Of Scala 2009\n",
      "22. Stopping Bad Guys From Using My Open Source Project Feedback Wanted\n",
      "23. A New Myth Appeared During The Presidential Campaign Of Andrew Jackson\n",
      "24. Zero Knowlege Proof Of Compositeness\n",
      "25. Show Hn: Network Monitor A Gui To Spot Anomalous Connections On Your Linux\n",
      "26. Hardening The C Standard Library At Scale\n",
      "27. Anthony Bourdain S Lost Li St S\n",
      "28. Bronze Age Mega-settlement In Kazakhstan Has Advanced Urban Planning, Metallurgy\n",
      "29. The Crdt Dictionary: A Field Guide To Conflict-free Replicated Data Types\n",
      "30. Student Perceptions Of Ai Coding Assistants In Learning\n",
      "31. Accessowl Yc S22 Is Hiring A Technical Account Manager Iam\n",
      "32. Let Go Of Stackoverflow Communities Must Take Ownership\n",
      "33. 1964 Recompiling Engine Documentation 2001 Pdf\n",
      "34. Post-mortem Of Shai-hulud Attack On November 24th, 2025\n",
      "35. We Re Learning More About What Vitamin D Does\n",
      "36. Dilution Vs Risk Taking: Capital Gains Taxes And Entrepreneurs\n",
      "37. Hachi: An Image Search Engine\n",
      "38. Mint Is Not Tex\n",
      "39. Dns Loc Record 2014\n",
      "40. Generating Cats With Learned Lookup Tables\n"
     ]
    }
   ],
   "source": [
    "# fetch_trends_alternative.py\n",
    "# يجلب \"ترندات\" من مصادر عامة بديلة (Hacker News + Reddit)\n",
    "# يكتب نتائج نظيفة وفريدة إلى trends_list.txt\n",
    "from pathlib import Path\n",
    "import requests, time, re, os\n",
    "\n",
    "OUT_FILE = Path(\"trends_list.txt\")\n",
    "TOP_N = 40             # عدد العناصر التي نحاول حفظها\n",
    "HN_MAX = 60            # عدد الـ top IDs من Hacker News لنحاول\n",
    "REDDIT_LIMIT = 60      # limit for reddit results\n",
    "TIMEOUT = 8\n",
    "HEADERS = {\"User-Agent\": \"trend-fetcher-script/1.0 (+https://example.com)\"}\n",
    "\n",
    "SAMPLE_FALLBACK = [\n",
    "    \"Artificial Intelligence\",\n",
    "    \"Healthy Eating\",\n",
    "    \"Sustainable Energy\",\n",
    "    \"Remote Work Trends\",\n",
    "    \"Mental Health Tips\",\n",
    "    \"Smart Home Gadgets\",\n",
    "    \"Personal Finance Tips\",\n",
    "    \"Home Workouts\",\n",
    "    \"Climate Action News\",\n",
    "    \"Electric Vehicles\"\n",
    "]\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    t = str(s).strip()\n",
    "    # احتفاظ بالعربية والحروف والأرقام وبعض الرموز المفيدة، حذف الباقي\n",
    "    t = re.sub(r'[^A-Za-z\\u0600-\\u06FF0-9\\s\\-\\:\\,]', ' ', t)\n",
    "    t = re.sub(r'\\s{2,}', ' ', t).strip()\n",
    "    # افتح أول حرف كبير للإنجليزية لتحسين المظهر\n",
    "    def cap_word(w):\n",
    "        return w.capitalize() if re.search(r'[A-Za-z]', w) else w\n",
    "    return \" \".join(cap_word(x) for x in t.split())\n",
    "\n",
    "def try_hackernews():\n",
    "    base = \"https://hacker-news.firebaseio.com/v0\"\n",
    "    try:\n",
    "        r = requests.get(f\"{base}/topstories.json\", headers=HEADERS, timeout=TIMEOUT)\n",
    "        r.raise_for_status()\n",
    "        ids = r.json()\n",
    "        out = []\n",
    "        count = 0\n",
    "        for id_ in ids[:HN_MAX]:\n",
    "            try:\n",
    "                it = requests.get(f\"{base}/item/{id_}.json\", headers=HEADERS, timeout=TIMEOUT)\n",
    "                it.raise_for_status()\n",
    "                data = it.json() or {}\n",
    "                title = data.get(\"title\") or \"\"\n",
    "                title = clean_text(title)\n",
    "                if title:\n",
    "                    out.append(title)\n",
    "                    count += 1\n",
    "                if count >= TOP_N:\n",
    "                    break\n",
    "            except Exception:\n",
    "                # لا نوقف الكل بسبب خطأ في عنصر واحد\n",
    "                time.sleep(0.12)\n",
    "                continue\n",
    "        return out\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def try_reddit():\n",
    "    # r/all top of day (public JSON endpoint). قد يحتاج User-Agent\n",
    "    url = f\"https://www.reddit.com/r/all/top.json?limit={REDDIT_LIMIT}&t=day\"\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=TIMEOUT)\n",
    "        r.raise_for_status()\n",
    "        j = r.json()\n",
    "        out = []\n",
    "        for child in j.get(\"data\", {}).get(\"children\", []):\n",
    "            d = child.get(\"data\", {})\n",
    "            title = d.get(\"title\") or \"\"\n",
    "            title = clean_text(title)\n",
    "            if title:\n",
    "                out.append(title)\n",
    "            if len(out) >= TOP_N:\n",
    "                break\n",
    "        return out\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def try_sources():\n",
    "    results = []\n",
    "    # 1) Hacker News\n",
    "    hn = try_hackernews()\n",
    "    if hn:\n",
    "        results.extend(hn)\n",
    "    # 2) Reddit\n",
    "    rd = try_reddit()\n",
    "    if rd:\n",
    "        results.extend(rd)\n",
    "    # more sources could be added here\n",
    "    return results\n",
    "\n",
    "def write_trends(trends):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for t in trends:\n",
    "        key = t.lower().strip()\n",
    "        if not key or key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(t)\n",
    "        if len(out) >= TOP_N:\n",
    "            break\n",
    "    if not out:\n",
    "        out = SAMPLE_FALLBACK.copy()\n",
    "    OUT_FILE.write_text(\"\\n\".join(out), encoding=\"utf-8\")\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    print(\"Starting alternative trend fetch (HN + Reddit) ...\")\n",
    "    # optionally use proxies from env if set\n",
    "    # requests will automatically use HTTP_PROXY/HTTPS_PROXY env vars\n",
    "    combined = try_sources()\n",
    "    if not combined:\n",
    "        print(\"No live trends fetched from sources. Falling back to sample list.\")\n",
    "    saved = write_trends(combined)\n",
    "    print(f\"Saved {len(saved)} trends to {OUT_FILE}\")\n",
    "    for i,t in enumerate(saved[:TOP_N], 1):\n",
    "        print(f\"{i}. {t}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3174114-f7ca-4678-ad65-d7b66cbbea09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
