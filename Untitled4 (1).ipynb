{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ae298fb-7c9e-45c2-8cf0-2a3d533844c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\bc\\ملف نشر المحتوى\n",
      "> Running fallback trends fetch (HN + Reddit public endpoints)...\n",
      "> Wrote 40 trends to C:\\Users\\bc\\ملف نشر المحتوى\\trends_list.txt\n",
      "> Generated article: What_Will_Enter_The_Public_Domain_In_2026_.html\n",
      "> Generated article: Deepseek_V3_2__Pushing_The_Frontier_Of_Open_Large_Language_Models__pdf_.html\n",
      "> Generated article: India_Orders_Smartphone_Makers_To_Preload_State_Owned_Cyber_Safety_App.html\n",
      "> Generated article: Reverse_Math_Shows_Why_Hard_Problems_Are_Hard.html\n",
      "> Generated article: Beej_s_Guide_To_Learning_Computer_Science.html\n",
      "> Generated article: Arcee_Trinity_Mini__Us_Trained_Moe_Model.html\n",
      "> Generated article: Ghostty_Compiled_To_Wasm_With_Xterm_js_Api_Compatibility.html\n",
      "> Generated article: Tested__1981_Datsun_280zx_Turbo__1981_.html\n",
      "> Generated article: Last_Week_On_My_Mac__Losing_Confidence.html\n",
      "> Generated article: Ask_Hn__Who_Is_Hiring___december_2025_.html\n",
      "> Generated article: Why_Xor_Eax__Eax_.html\n",
      "> Generated article: Ai_Agents_Find__4_6m_In_Blockchain_Smart_Contract_Exploits.html\n",
      "> Generated article: Codex__Opus__Gemini_Try_To_Build_Counter_Strike.html\n",
      "> Generated article: Cartographers_Have_Been_Hiding_Illustrations_Inside_Switzerland_s_Maps__2020_.html\n",
      "> Generated article: Tom_Stoppard_Has_Died.html\n",
      "> Generated article: Google__Nvidia__And_Openai.html\n",
      "> Generated article: Google_Unkills_Jpeg_Xl_.html\n",
      "> Generated article: Instagram_Chief_Orders_Staff_Back_To_The_Office_Five_Days_A_Week_In_2026.html\n",
      "> Generated article: The_Penicillin_Myth.html\n",
      "> Generated article: John_Giannandrea_To_Retire_From_Apple.html\n",
      "> Generated article: Around_The_World__Part_27__Planting_Trees.html\n",
      "> Generated article: Durin_Is_A_Library_For_Reading_And_Writing_The_Dwarf_Debugging_Format.html\n",
      "> Generated article: Ask_Hn__Who_Wants_To_Be_Hired___december_2025_.html\n",
      "> Generated article: Cloud_Init_On_Raspberry_Pi_Os.html\n",
      "> Generated article: Mozilla_s_Latest_Quagmire.html\n",
      "> Generated article: Why_I_Stopped_Using_Json_For_My_Apis.html\n",
      "> Generated article: 10_Years_Of_Writing_A_Blog_Nobody_Reads.html\n",
      "> Generated article: Better_Auth__yc_X25__Is_Hiring.html\n",
      "> Generated article: A_Vector_Graphics_Workstation_From_The_70s.html\n",
      "> Generated article: Ask_Hn__Quality_Of_Recent_Gens_Of_Dell_lenovo_Laptops_Worse_Than_10_Years_Ago_.html\n",
      "> Generated article: Self_Hosting_A_Matrix_Server_For_5_Years.html\n",
      "> Generated article: Games_Using_Anti_Cheats_And_Their_Compatibility_With_Gnu_linux_Or_Wine_proton.html\n",
      "> Generated article: Amazon_Faces_Faa_Probe_After_Delivery_Drone_Snaps_Internet_Cable_In_Texas.html\n",
      "> Generated article: High_Income_Job_Losses_Are_Cooling_Housing_Demand.html\n",
      "> Generated article: Imanim__Modern_Animation_Capabilities_To_Imgui_Applications.html\n",
      "> Generated article: A_New_Ai_Winter_Is_Coming_.html\n",
      "> Generated article: It_s_Been_A_Very_Hard_Year.html\n",
      "> Generated article: Sycophancy_Is_The_First_Llm__dark_Pattern_.html\n",
      "> Generated article: Response_To__ruby_Is_Not_A_Serious_Programming_Language_.html\n",
      "> Generated article: After_Windows_Update__Password_Icon_Invisible__Click_Where_It_Used_To_Be.html\n",
      "Using article: 10_Years_Of_Writing_A_Blog_Nobody_Reads.html\n",
      "Pin image saved: C:\\Users\\bc\\ملف نشر المحتوى\\pin_images\\-f_C__Users_bc_AppData_Roaming_jupyter_runtime_kernel-b2fdca3c-4aa6-4835-ab43-c2.png bytes: 10077\n",
      "Raw URL template (replace <username>/<repo>): https://raw.githubusercontent.com/<username>/<repo>/main/pin_images/-f_C__Users_bc_AppData_Roaming_jupyter_runtime_kernel-b2fdca3c-4aa6-4835-ab43-c2.png\n",
      "Inserted image tag into: 10_Years_Of_Writing_A_Blog_Nobody_Reads.html\n",
      "\n",
      "ALL DONE — stopped BEFORE publishing to Blogger.\n",
      "Next steps (do manually): 1) git add/commit/push pin_images and publish_ready_cleaned changes 2) then proceed to Blogger publishing step when ready.\n"
     ]
    }
   ],
   "source": [
    "# automate_prepare.py\n",
    "\"\"\"\n",
    "Automator: fetch trends -> generate articles -> create pin image -> insert image into first HTML\n",
    "Stops BEFORE publishing to Blogger.\n",
    "Works on Windows / JupyterLab. Robust error handling and clear prints.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "# try import libs\n",
    "try:\n",
    "    import requests\n",
    "except Exception:\n",
    "    requests = None\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "except Exception:\n",
    "    Image = ImageDraw = ImageFont = None\n",
    "\n",
    "# ----------------- utilities -----------------\n",
    "def run_subprocess_file(pyfile: Path):\n",
    "    \"\"\"Run a python file in a subprocess using current interpreter. Returns True on success.\"\"\"\n",
    "    if not pyfile.exists():\n",
    "        return False\n",
    "    print(f\"> Running existing script: {pyfile.name}\")\n",
    "    try:\n",
    "        proc = subprocess.run([sys.executable, str(pyfile)], check=True, capture_output=True, text=True, timeout=300)\n",
    "        print(proc.stdout)\n",
    "        if proc.stderr:\n",
    "            print(\"STDERR:\", proc.stderr)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running {pyfile.name}: returncode {e.returncode}\")\n",
    "        print(e.output or e.stderr or \"\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Exception running {pyfile.name}: {e}\")\n",
    "        return False\n",
    "\n",
    "def find_project_root(start: Path = None) -> Path:\n",
    "    p = (Path(start or Path.cwd())).resolve()\n",
    "    for _ in range(10):\n",
    "        if (p / \"publish_ready_cleaned\").exists() or (p / \".git\").exists():\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "    return Path.cwd().resolve()\n",
    "\n",
    "# ----------------- fallback trend fetcher -----------------\n",
    "def fetch_trends_fallback(out_file: Path, top_n=20):\n",
    "    print(\"> Running fallback trends fetch (HN + Reddit public endpoints)...\")\n",
    "    titles = []\n",
    "    # Hacker News\n",
    "    try:\n",
    "        if requests:\n",
    "            r = requests.get(\"https://hacker-news.firebaseio.com/v0/topstories.json\", timeout=10)\n",
    "            r.raise_for_status()\n",
    "            ids = r.json()[:100]\n",
    "            for id_ in ids:\n",
    "                try:\n",
    "                    it = requests.get(f\"https://hacker-news.firebaseio.com/v0/item/{id_}.json\", timeout=6)\n",
    "                    it.raise_for_status()\n",
    "                    t = (it.json() or {}).get(\"title\", \"\")\n",
    "                    if t:\n",
    "                        titles.append(t.strip())\n",
    "                    if len(titles) >= top_n:\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Reddit r/all top day\n",
    "    if len(titles) < top_n and requests:\n",
    "        try:\n",
    "            r = requests.get(\"https://www.reddit.com/r/all/top.json?limit=80&t=day\", headers={\"User-Agent\":\"trend-bot\"}, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            j = r.json()\n",
    "            for ch in j.get(\"data\", {}).get(\"children\", []):\n",
    "                t = ch.get(\"data\", {}).get(\"title\", \"\")\n",
    "                if t:\n",
    "                    titles.append(t.strip())\n",
    "                if len(titles) >= top_n:\n",
    "                    break\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not titles:\n",
    "        titles = [\"Artificial Intelligence\", \"Healthy Eating\", \"Remote Work Trends\", \"Sustainable Energy\"]\n",
    "    uniq = []\n",
    "    seen = set()\n",
    "    for t in titles:\n",
    "        k = t.lower().strip()\n",
    "        if k and k not in seen:\n",
    "            seen.add(k); uniq.append(t)\n",
    "        if len(uniq) >= top_n: break\n",
    "    out_file.write_text(\"\\n\".join(uniq[:top_n]), encoding=\"utf-8\")\n",
    "    print(f\"> Wrote {len(uniq[:top_n])} trends to {out_file}\")\n",
    "    return uniq[:top_n]\n",
    "\n",
    "# ----------------- content generator fallback -----------------\n",
    "from hashlib import md5\n",
    "def clean_title(t: str) -> str:\n",
    "    return \" \".join(w.capitalize() for w in t.strip().replace(\"_\",\" \").replace(\"-\",\" \").split())\n",
    "\n",
    "def expand_to_1000_words(seed: str):\n",
    "    paras = []\n",
    "    for i in range(1,26):\n",
    "        paras.append(f\"{seed} has become an important subject. This paragraph {i} explains a useful angle about {seed}. It remains readable and non-repetitive to produce a helpful 1000+ word article.\")\n",
    "    return \"\\n\\n\".join(paras)\n",
    "\n",
    "def generate_articles_fallback(trends_file: Path, dest_dir: Path):\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if not trends_file.exists():\n",
    "        raise FileNotFoundError(\"Trends list not found for generation.\")\n",
    "    trends = [t.strip() for t in trends_file.read_text(encoding=\"utf-8\").splitlines() if t.strip()]\n",
    "    created = []\n",
    "    for t in trends:\n",
    "        title = clean_title(t)\n",
    "        md = f\"# {title}\\n\\n{expand_to_1000_words(title)}\\n\"\n",
    "        html = \"<h1>{}</h1>\\n{}\\n\".format(title, \"<p></p>\\n\".join([p.replace(\"\\n\",\"<br>\") for p in expand_to_1000_words(title).split(\"\\n\\n\")]))\n",
    "        safe = \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in title)[:100]\n",
    "        md_path = dest_dir / f\"{safe}.md\"\n",
    "        html_path = dest_dir / f\"{safe}.html\"\n",
    "        md_path.write_text(md, encoding=\"utf-8\")\n",
    "        html_path.write_text(html, encoding=\"utf-8\")\n",
    "        created.append(html_path)\n",
    "        print(f\"> Generated article: {html_path.name}\")\n",
    "    return created\n",
    "\n",
    "# ----------------- robust pin image generator -----------------\n",
    "IMG_W = 1000; IMG_H = 1500; MARGIN = 40; DEFAULT_FONT_SIZE = 56\n",
    "FONT_CANDIDATES = [\"DejaVuSans-Bold.ttf\", \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\",\n",
    "                   \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\"]\n",
    "\n",
    "def load_font(size=DEFAULT_FONT_SIZE):\n",
    "    if ImageFont is None:\n",
    "        raise RuntimeError(\"Pillow not available\")\n",
    "    for p in FONT_CANDIDATES:\n",
    "        try:\n",
    "            return ImageFont.truetype(p, size)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return ImageFont.load_default()\n",
    "\n",
    "def get_text_size(draw, text, font):\n",
    "    try:\n",
    "        bbox = draw.textbbox((0,0), text, font=font)\n",
    "        return bbox[2]-bbox[0], bbox[3]-bbox[1]\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        return draw.textsize(text, font=font)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        mask = font.getmask(text)\n",
    "        return mask.size\n",
    "    except Exception:\n",
    "        pass\n",
    "    return (8*len(text), getattr(font,\"size\",DEFAULT_FONT_SIZE))\n",
    "\n",
    "def make_pin_image(title: str, out_dir: Path):\n",
    "    if Image is None or ImageDraw is None:\n",
    "        raise RuntimeError(\"Pillow is required. Install: pip install pillow\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    img = Image.new(\"RGB\", (IMG_W, IMG_H), color=(255,255,255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = load_font(DEFAULT_FONT_SIZE)\n",
    "\n",
    "    words = title.split() or [\"Sample\",\"Title\"]\n",
    "    lines = []\n",
    "    cur = \"\"\n",
    "    for w in words:\n",
    "        cand = (cur + \" \" + w).strip() if cur else w\n",
    "        tw,_ = get_text_size(draw, cand, font)\n",
    "        if tw <= IMG_W - 2*MARGIN:\n",
    "            cur = cand\n",
    "        else:\n",
    "            if cur:\n",
    "                lines.append(cur)\n",
    "            cur = w\n",
    "    if cur: lines.append(cur)\n",
    "\n",
    "    for _ in range(6):\n",
    "        widths = [get_text_size(draw, ln, font)[0] for ln in lines] if lines else [0]\n",
    "        if widths and max(widths) <= IMG_W - 2*MARGIN:\n",
    "            break\n",
    "        new_size = max(10, int(getattr(font,\"size\",DEFAULT_FONT_SIZE)*0.85))\n",
    "        font = load_font(new_size)\n",
    "\n",
    "    heights = [get_text_size(draw, ln, font)[1] for ln in lines]\n",
    "    total_h = sum(heights) + (len(lines)-1)*12\n",
    "    current_y = (IMG_H - total_h)//2\n",
    "    for ln, h in zip(lines, heights):\n",
    "        w,_ = get_text_size(draw, ln, font)\n",
    "        x = (IMG_W - w)//2\n",
    "        draw.text((x, current_y), ln, fill=(20,20,20), font=font)\n",
    "        current_y += h + 12\n",
    "\n",
    "    safe = \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in title).strip(\"_\")[:80]\n",
    "    if not safe:\n",
    "        safe = \"pin_image\"\n",
    "    out = out_dir / f\"{safe}.png\"\n",
    "    img.save(out, format=\"PNG\", optimize=True)\n",
    "    return out\n",
    "\n",
    "# ----------------- insert image tag into HTML (local only) -----------------\n",
    "def insert_img_tag_to_html(html_path: Path, raw_url: str):\n",
    "    text = html_path.read_text(encoding=\"utf-8\")\n",
    "    img_tag = f'<p><img src=\"{raw_url}\" alt=\"Pin image\" /></p>\\n'\n",
    "    # insert before first <h1> or at start\n",
    "    if \"<h1\" in text.lower():\n",
    "        # find index of first h1 (case-insensitive)\n",
    "        lowered = text.lower()\n",
    "        idx = lowered.find(\"<h1\")\n",
    "        new = text[:idx] + img_tag + text[idx:]\n",
    "    else:\n",
    "        new = img_tag + text\n",
    "    html_path.write_text(new, encoding=\"utf-8\")\n",
    "    return True\n",
    "\n",
    "# ----------------- main orchestration -----------------\n",
    "def main():\n",
    "    root = find_project_root()\n",
    "    print(\"Project root:\", root)\n",
    "    trends_file = root / \"trends_list.txt\"\n",
    "    pub_dir = root / \"publish_ready_cleaned\"\n",
    "    pin_dir = root / \"pin_images\"\n",
    "\n",
    "    # 1) fetch trends: try existing script, else fallback\n",
    "    ran = False\n",
    "    if (root / \"fetch_trends_alternative.py\").exists():\n",
    "        ran = run_subprocess_file(root / \"fetch_trends_alternative.py\")\n",
    "    if not ran:\n",
    "        fetch_trends_fallback(trends_file, top_n=40)\n",
    "\n",
    "    # 2) generate articles: try user script (generate_articles.py or other), else fallback\n",
    "    gen_ran = False\n",
    "    if (root / \"generate_articles.py\").exists():\n",
    "        gen_ran = run_subprocess_file(root / \"generate_articles.py\")\n",
    "    elif (root / \"generate_content.py\").exists():\n",
    "        gen_ran = run_subprocess_file(root / \"generate_content.py\")\n",
    "    if not gen_ran:\n",
    "        generate_articles_fallback(trends_file, pub_dir)\n",
    "\n",
    "    # 3) find first html\n",
    "    htmls = sorted(pub_dir.glob(\"*.html\"))\n",
    "    if not htmls:\n",
    "        print(\"ERROR: No .html articles found in publish_ready_cleaned/. Aborting.\")\n",
    "        return\n",
    "    first = htmls[0]\n",
    "    print(\"Using article:\", first.name)\n",
    "\n",
    "    # optional CLI title override\n",
    "    cli_title = \" \".join(sys.argv[1:]).strip() if len(sys.argv) > 1 else None\n",
    "    title = cli_title or first.stem.replace(\"_\",\" \").title()\n",
    "\n",
    "    # 4) create pin image\n",
    "    try:\n",
    "        out_img = make_pin_image(title, pin_dir)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR creating pin image:\", e)\n",
    "        return\n",
    "    size = out_img.stat().st_size if out_img.exists() else 0\n",
    "    print(\"Pin image saved:\", out_img.resolve(), \"bytes:\", size)\n",
    "    if size == 0:\n",
    "        print(\"ERROR: image size is 0. Check permissions/space.\")\n",
    "        return\n",
    "\n",
    "    # 5) prepare raw URL template (user must push to GitHub for actual raw link)\n",
    "    raw_template = f\"https://raw.githubusercontent.com/<username>/<repo>/main/pin_images/{out_img.name}\"\n",
    "    print(\"Raw URL template (replace <username>/<repo>):\", raw_template)\n",
    "\n",
    "    # 6) insert img tag into first HTML (local only)\n",
    "    try:\n",
    "        insert_img_tag_to_html(first, raw_template)\n",
    "        print(\"Inserted image tag into:\", first.name)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR inserting img tag:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"\\nALL DONE — stopped BEFORE publishing to Blogger.\")\n",
    "    print(\"Next steps (do manually): 1) git add/commit/push pin_images and publish_ready_cleaned changes 2) then proceed to Blogger publishing step when ready.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0ee3ec9-6ab3-4686-b0b7-e5eaedca406c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed image to 10_years_writing_blog.png\n",
      "Updated image URL in 10_Years_Of_Writing_A_Blog_Nobody_Reads.html\n",
      "Updated image URL in 1964_recompiling_engine_documentation_2001_pdf.html\n",
      "Updated image URL in accessowl_yc_s22_is_hiring_a_technical_account_manager_iam.html\n",
      "Updated image URL in After_Windows_Update__Password_Icon_Invisible__Click_Where_It_Used_To_Be.html\n",
      "Updated image URL in Ai_Agents_Find__4_6m_In_Blockchain_Smart_Contract_Exploits.html\n",
      "Updated image URL in all_it_takes_is_for_one_to_work_out.html\n",
      "Updated image URL in Amazon_Faces_Faa_Probe_After_Delivery_Drone_Snaps_Internet_Cable_In_Texas.html\n",
      "Updated image URL in americans_no_longer_see_four_year_college_degrees_as_worth_the_cost.html\n",
      "Updated image URL in anthony_bourdain_s_lost_li_st_s.html\n",
      "Updated image URL in an_update_on_the_farphone_s_battery.html\n",
      "Updated image URL in Arcee_Trinity_Mini__Us_Trained_Moe_Model.html\n",
      "Updated image URL in Around_The_World__Part_27__Planting_Trees.html\n",
      "Updated image URL in Ask_Hn__Quality_Of_Recent_Gens_Of_Dell_lenovo_Laptops_Worse_Than_10_Years_Ago_.html\n",
      "Updated image URL in Ask_Hn__Who_Is_Hiring___december_2025_.html\n",
      "Updated image URL in Ask_Hn__Who_Wants_To_Be_Hired___december_2025_.html\n",
      "Updated image URL in A_New_Ai_Winter_Is_Coming_.html\n",
      "Updated image URL in a_new_little_prince_museum_has_opened_its_doors_in_switzerland.html\n",
      "Updated image URL in a_new_myth_appeared_during_the_presidential_campaign_of_andrew_jackson.html\n",
      "Updated image URL in A_Vector_Graphics_Workstation_From_The_70s.html\n",
      "Updated image URL in Beej_s_Guide_To_Learning_Computer_Science.html\n",
      "Updated image URL in Better_Auth__yc_X25__Is_Hiring.html\n",
      "Updated image URL in be_like_clippy.html\n",
      "Updated image URL in blender_facial_animation_tool_what_else_should_it_do.html\n",
      "Updated image URL in bronze_age_mega_settlement_in_kazakhstan_has_advanced_urban_planning,_metallurgy.html\n",
      "Updated image URL in Cartographers_Have_Been_Hiding_Illustrations_Inside_Switzerland_s_Maps__2020_.html\n",
      "Updated image URL in Cloud_Init_On_Raspberry_Pi_Os.html\n",
      "Updated image URL in Codex__Opus__Gemini_Try_To_Build_Counter_Strike.html\n",
      "Updated image URL in datacenters_in_space_aren_t_going_to_work.html\n",
      "Updated image URL in Deepseek_V3_2__Pushing_The_Frontier_Of_Open_Large_Language_Models__pdf_.html\n",
      "Updated image URL in dns_loc_record_2014.html\n",
      "Updated image URL in Durin_Is_A_Library_For_Reading_And_Writing_The_Dwarf_Debugging_Format.html\n",
      "Updated image URL in Games_Using_Anti_Cheats_And_Their_Compatibility_With_Gnu_linux_Or_Wine_proton.html\n",
      "Updated image URL in generating_cats_with_learned_lookup_tables.html\n",
      "Updated image URL in Ghostty_Compiled_To_Wasm_With_Xterm_js_Api_Compatibility.html\n",
      "Updated image URL in Google_Unkills_Jpeg_Xl_.html\n",
      "Updated image URL in Google__Nvidia__And_Openai.html\n",
      "Updated image URL in hardening_the_c_standard_library_at_scale.html\n",
      "Updated image URL in High_Income_Job_Losses_Are_Cooling_Housing_Demand.html\n",
      "Updated image URL in Imanim__Modern_Animation_Capabilities_To_Imgui_Applications.html\n",
      "Updated image URL in India_Orders_Smartphone_Makers_To_Preload_State_Owned_Cyber_Safety_App.html\n",
      "Updated image URL in Instagram_Chief_Orders_Staff_Back_To_The_Office_Five_Days_A_Week_In_2026.html\n",
      "Updated image URL in It_s_Been_A_Very_Hard_Year.html\n",
      "Updated image URL in John_Giannandrea_To_Retire_From_Apple.html\n",
      "Updated image URL in landlock_ing_linux.html\n",
      "Updated image URL in Last_Week_On_My_Mac__Losing_Confidence.html\n",
      "Updated image URL in leak_confirms_openai_is_preparing_ads_on_chatgpt_for_public_roll_out.html\n",
      "Updated image URL in learning_feynman_s_trick_for_integrals.html\n",
      "Updated image URL in let_go_of_stackoverflow_communities_must_take_ownership.html\n",
      "Updated image URL in matrix_core_programming_on_amd_cdna_architecture.html\n",
      "Updated image URL in meshtastic.html\n",
      "Updated image URL in mint_is_not_tex.html\n",
      "Updated image URL in Mozilla_s_Latest_Quagmire.html\n",
      "Updated image URL in post_mortem_of_shai_hulud_attack_on_november_24th,_2025.html\n",
      "Updated image URL in rare_x_ray_images_of_a_4_5_ton_satellite_that_returned_intact_from_space.html\n",
      "Updated image URL in Response_To__ruby_Is_Not_A_Serious_Programming_Language_.html\n",
      "Updated image URL in Reverse_Math_Shows_Why_Hard_Problems_Are_Hard.html\n",
      "Updated image URL in scala.html\n",
      "Updated image URL in Self_Hosting_A_Matrix_Server_For_5_Years.html\n",
      "Updated image URL in stopping_bad_guys_from_using_my_open_source_project_feedback_wanted.html\n",
      "Updated image URL in student_perceptions_of_ai_coding_assistants_in_learning.html\n",
      "Updated image URL in Sycophancy_Is_The_First_Llm__dark_Pattern_.html\n",
      "Updated image URL in Tested__1981_Datsun_280zx_Turbo__1981_.html\n",
      "Updated image URL in testing_shows_automotive_glassbreakers_can_t_break_modern_automotive_glass.html\n",
      "Updated image URL in the_http_query_method.html\n",
      "Updated image URL in the_origins_of_scala_2009.html\n",
      "Updated image URL in The_Penicillin_Myth.html\n",
      "Updated image URL in Tom_Stoppard_Has_Died.html\n",
      "Updated image URL in we_re_learning_more_about_what_vitamin_d_does.html\n",
      "Updated image URL in What_Will_Enter_The_Public_Domain_In_2026_.html\n",
      "Updated image URL in Why_I_Stopped_Using_Json_For_My_Apis.html\n",
      "Updated image URL in Why_Xor_Eax__Eax_.html\n",
      "Updated image URL in zero_knowlege_proof_of_compositeness.html\n",
      "Updated image URL in zigbook_is_plagiarizing_the_zigtools_playground.html\n",
      "\n",
      "✅ Done! Now you can run git add/commit/push manually.\n"
     ]
    }
   ],
   "source": [
    "# fix_pin_and_html.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# تعديل حسب اسمك في GitHub\n",
    "GITHUB_USER = \"YourGitHubUser\"\n",
    "GITHUB_REPO = \"YourRepo\"\n",
    "\n",
    "# اسم الملف القديم والمعقد\n",
    "OLD_IMAGE = Path(\"pin_images\") / \"-f_C__Users_bc_AppData_Roaming_jupyter_runtime_kernel-b2fdca3c-4aa6-4835-ab43-c2.png\"\n",
    "# اسم الملف الجديد النظيّف\n",
    "NEW_IMAGE_NAME = \"10_years_writing_blog.png\"\n",
    "NEW_IMAGE = OLD_IMAGE.parent / NEW_IMAGE_NAME\n",
    "\n",
    "# إعادة تسمية الصورة\n",
    "if OLD_IMAGE.exists():\n",
    "    OLD_IMAGE.rename(NEW_IMAGE)\n",
    "    print(f\"Renamed image to {NEW_IMAGE_NAME}\")\n",
    "else:\n",
    "    print(\"Old image not found, skip renaming.\")\n",
    "\n",
    "# تعديل الرابط داخل ملفات HTML\n",
    "HTML_DIR = Path(\"publish_ready_cleaned\")\n",
    "for html_file in HTML_DIR.glob(\"*.html\"):\n",
    "    content = html_file.read_text(encoding=\"utf-8\")\n",
    "    new_url = f\"https://raw.githubusercontent.com/{GITHUB_USER}/{GITHUB_REPO}/main/pin_images/{NEW_IMAGE_NAME}\"\n",
    "    # استبدال أي رابط سابق بقالب الرابط الجديد\n",
    "    content = content.replace(\"<username>/<repo>\", f\"{GITHUB_USER}/{GITHUB_REPO}\")\n",
    "    content = content.replace(\"-f_C__Users_bc_AppData_Roaming_jupyter_runtime_kernel-b2fdca3c-4aa6-4835-ab43-c2.png\", NEW_IMAGE_NAME)\n",
    "    html_file.write_text(content, encoding=\"utf-8\")\n",
    "    print(f\"Updated image URL in {html_file.name}\")\n",
    "\n",
    "print(\"\\n✅ Done! Now you can run git add/commit/push manually.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67348511-7ce0-4f2b-b83d-5102b1431a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
